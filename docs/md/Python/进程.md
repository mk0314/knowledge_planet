<!--
 * @Author: mengkun822 1197235402@qq.com
 * @Date: 2023-06-12 14:14:03
 * @LastEditors: mengkun822 1197235402@qq.com
 * @LastEditTime: 2023-06-12 19:37:38
 * @FilePath: \knowledge_planet\docs\md\Python\进程.md
 * @Description: 这是默认设置,请设置`customMade`, 打开koroFileHeader查看配置 进行设置: https://github.com/OBKoro1/koro1FileHeader/wiki/%E9%85%8D%E7%BD%AE
-->

> ### 进程

进程（Process）是计算机中的一种基本概念，它是指正在运行的程序在操作系统中的实例。每个进程都有它自己的一些资源，包括内存、文件句柄等，在进程间相互隔离。操作系统控制着进程的创建、执行、挂起、恢复和销毁等过程。

在一个多任务的操作系统中，可以同时运行多个进程，每个进程都独立地运行在自己的虚拟空间中，相互之间不会互相干扰。进程的数量是有限的，因为每个进程都需要占用一定的系统资源，当系统资源不够时，就无法再创建新的进程。

每个进程都有自己的进程 ID（PID），通过进程 ID 可以区分不同的进程。进程还可以包含多个线程，这些线程共享进程的资源，在进程内部执行不同的任务，实现多任务并发执行。

进程有以下几个主要特点：

隔离性：每个进程都有自己独立的内存空间，对其他进程的内存空间不可见，相互之间不会干扰。

系统调用：进程通过系统调用来请求操作系统为其提供服务，例如读写文件、网络通信等。

进程调度：操作系统根据一定的调度算法来调度进程，控制其执行顺序和时间片分配。

进程通信：不同的进程可以通过进程间通信（IPC）机制来进行数据传输和共享资源，例如管道、信号、共享内存、消息队列等。但是这些机制都需要在进程之间建立一定的协议才能实现正确的通信。

进程是计算机中非常重要的概念，多进程编程也是程序员必须熟练掌握的技能之一。在 Python 中，可以使用 multiprocessing 模块来创建和管理多个进程，在多核 CPU 上实现并行计算，从而提高程序的效率。

```python

import os
# 进程创建

from multiprocessing import Process

from time import sleep


def task1(s, name):
    count = 0
    sleep(2)
    while True:
        sleep(s)
        if count == 4:
            break
        count += 1
        print('这是任务1。。。。。。。', os.getpid(), os.getppid(), name)


def task2(s, name):
    count = 0
    sleep(2)
    while True:
        sleep(s)
        if count == 4:
            break
        count += 1
        print('这是任务2。。。。。。。', os.getpid(), os.getppid(), name)


if __name__ == '__main__':
    print(os.getpid())
    # 子进程
    p1 = Process(target=task1, name="任务1", args=(1, 1))
    p1.start()
    print(p1.name, os.getpid(), os.getppid())
    p2 = Process(target=task2, name="任务2", args=(2, 2))
    p2.start()
    print(p2.name, os.getpid(), os.getppid())

""
运行结果：
7700
任务1 7700 18080
任务2 7700 18080
这是任务1。。。。。。。 14392 7700 1
这是任务1。。。。。。。 14392 7700 1
这是任务2。。。。。。。 15104 7700 2
这是任务1。。。。。。。 14392 7700 1
这是任务2。。。。。。。 15104 7700 2
这是任务1。。。。。。。 14392 7700 1
这是任务2。。。。。。。 15104 7700 2
这是任务2。。。。。。。 15104 7700 2
"""
```

> ### 自定义进程

```python

from multiprocessing import Process


class MyProcess(Process):
    def __init__(self, name):
        super(Process, self).__init__()
        self.name = name

    def run(self):
        n = 1
        while True:
            if n == 4:
                break
            print(f'{n} 自定义进程{self.name}')
            n += 1


if __name__ == '__main__':
    p = MyProcess('小明')
    p.start()

"""
结果：

1 自定义进程小明
2 自定义进程小明
3 自定义进程小明

"""
```

> ### 进程池之非阻塞式

当需要创建的子进程数量不多的时候，可以直接利用 multiprocessing 中的 Process 动态生成多个进程

但如果是上百个甚至上千个目标，手动的去创建进程的工作量巨大，此时就可以利用 multiprocessing 模块提供的 Pool 方法

初始化 Pool 时， 可以指定一个最大进程数， 当有新的请求提交到 Pool 中时，如果池还没有满

那么创建的一个新的进程用来执行该请求，但如果池中的进程数已经达到指定的最大值，那么该请求就会等待

直到池中有进程结束， 才会创建新的进程来执行

阻塞式：

非阻塞式：全部添加到队列中，立刻返回，并没等待其他进程完毕，但是回调函数是等待任务完成后才调用

> ### 非阻塞式进程

```python
import os
from multiprocessing import Process, Pool
import time
from random import random



# 非阻塞式进程
def task(task_name):
    print('开始任务了', task_name)
    start = time.time()
    time.sleep(random() *2)
    end = time.time()

    print('完成用时', end - start, f'进程id:{os.getpid()}')

if __name__ == '__main__':
    pool = Pool(5)
    tasks = ['听音乐', '吃饭', '洗衣服', '散步', '做饭']

    for task1 in tasks:
        pool.apply_async(task, args=(task1,))
    pool.close()
    pool.join()
    print('----------over----------')

"""
结果：

开始任务了 听音乐
开始任务了 吃饭
开始任务了 洗衣服
开始任务了 散步
开始任务了 做饭
完成用时 0.42551422119140625 进程id:7624
完成用时 0.8910746574401855 进程id:17008
完成用时 1.320955753326416 进程id:19780
完成用时 1.2820382118225098 进程id:7472
完成用时 1.6409945487976074 进程id:12828
----------over----------

"""

```

> ### 阻塞式进程

```python
import os
from multiprocessing import Process, Pool
import time
from random import random

def task(task_name):
    print('开始任务了', task_name)
    start = time.time()
    time.sleep(random() *2)
    end = time.time()
    print(f'完成{task_name},用时:{end - start},进程id:{os.getpid()}')

if __name__ == '__main__':
    pool = Pool(5)
    tasks = ['听音乐', '吃饭', '洗衣服', '散步', '做饭']
    for task1 in tasks:
        pool.apply(task, args=(task1,))
    pool.close()
    pool.join()
    print('----------over----------')



```

> ### 进程之间通信

```python
def task(task_name):
    print('开始任务了', task_name)
    start = time.time()
    time.sleep(random() * 2)
    end = time.time()

    print('完成用时', end - start, f'进程id:{os.getpid()}')


def callback_func(n):
    print(n, 'callback')


if __name__ == '__main__':

    q = Queue(5)
    q.put('A')
    q.put('B')
    q.put('C')
    q.put('D')
    q.put('E')
    print(q.qsize())
    if not q.full():
        q.put('F', timeout=3)  # 如果Queue则只能等待，除非有空地则添加成功
    else:
        print('queue已经满了')

    print(q.get(timeout=2))
    print(q.get(timeout=2))
    print(q.get(timeout=2))
    print(q.get(timeout=2))
    print(q.get(timeout=2))
    pool = Pool(3)
    tasks = ['听音乐', '吃饭', '洗衣服', '散步', '做饭']

    for task1 in tasks:
        pool.apply_async(task, args=(task1,), callback=callback_func)
    pool.close()
    pool.join()
    print('----------over----------')
    p = MyProcess('小明')
    p.start()

"""
结果：

5
queue已经满了
A
B
C
D
E
开始任务了 听音乐
开始任务了 吃饭
开始任务了 洗衣服
完成用时 0.15370965003967285 进程id:11248
开始任务了 散步
None callback
完成用时 0.9761219024658203 进程id:7576
None callback
开始任务了 做饭
完成用时 1.6512377262115479 进程id:16564
None callback
完成用时 1.5544276237487793 进程id:11248
None callback
完成用时 1.4023268222808838 进程id:7576
None callback
----------over----------
1 自定义进程小明
2 自定义进程小明
3 自定义进程小明


"""
```

```python

from multiprocessing import Process, Queue
import time


def download(q):
    images = ['a.png', 'b.png', 'c.png']

    for image in images:
        print('正在下载', image)
        time.sleep(4)
        q.put(image)


def getfile(q):
    while True:
        try:
            image = q.get(timeout=5)
            print(f'{image}保存成功')
        except Exception as err:
            print(err)
            break


if __name__ == '__main__':
    q = Queue(5)
    p1 = Process(target=download, args=(q, ))
    p2 = Process(target=getfile, args=(q, ))
    p1.start()
    p1.join()
    p2.start()
    p2.join()
    print('----over-----')

"""
结果：

正在下载 a.png
正在下载 b.png
正在下载 c.png
a.png保存成功
b.png保存成功
c.png保存成功

----over-----

"""

```

> ### 多线程

多线程顾名思义就是再同一个进程中创建多个线程并执行并发不同任务，充分的利用 cpu 资源，提高 cpu 的运行效率，不同线程之间可以共享内存空间和系统资源

优点：

1. 资源开销比较小：不同线程之间可以共享内存空间和系统资源
2. 响应速度快： 线程资源共享的内存空间，在通信上数据交换方便
3. 提高运行效率：充分利用多核 CPU，从而使得程序并行执行，提高效率

```python

""""
Process: 进程
threading： 线程
"""

import threading
from multiprocessing import Process, Queue
import time

def download(q):
    images = ['a.png', 'b.png', 'c.png']

    for image in images:
        print('正在下载', image)
        time.sleep(4)


def listen_music(q):
    musics = ['aaa', 'bbb', 'ccc', 'ddd']
    for music in musics:
        print(f'正在收听{music}')
        time.sleep(4)


if __name__ == '__main__':
    t = threading.Thread(target=download, name=1, args=(1, ))
    t1 = threading.Thread(target=listen_music, name=1, args=(1, ))
    t.start()
    t1.start()
    n = 1
    while True:
        print(n)
        if n > 3:
            break
        time.sleep(5)
        n += 1

    print('----over-----')

"""
结果：

正在下载 a.png
正在收听aaa
1
正在收听bbb正在下载
b.png
2
正在收听ccc
正在下载 c.png
3
正在收听ddd
4
----over-----

"""

```

> ### 多线程同步

共享数据：
如果多个线程对某个数据修改， 则可能出现不可预料的结果，为了保证数据的正确性， 需要对多个线程进行同步。

同步： 一个线程一个线程的完成，一个做完才能运行另一个进来。

同步线程时效率会降低

使用 thread 对象的 lock 和 Rlock 可以现实简单的线程同步， 这两个对象都有 acquire 方法和 release 方法，对于那些需要每次只允许一个线程操作的数据，可以将其操作放到 acquire 觉 release 方法之间

多线程的优势在于可以同时运行多个任务, 但是当线程需要共享数据的时候，可能存在数据不同步的问题，引入锁的概念

```python


lock = threading.Lock()

lock.acquire # 请求得到锁
lock.release #释放锁

```

```python

import threading
import random
import time

lock = threading.Lock()

list1 = [0] * 10


def task1():
    # 获取线程锁，如果已经上锁，则等待锁的释放
    lock.acquire() # 阻塞
    for i in range(len(list1)):
        print('------------>', i)
        list1[i] = 1
        time.sleep(0.5)
    lock.release()


def task2():
    # 获取线程锁，如果已经上锁，则等待锁的释放
    lock.acquire()  # 阻塞
    for i in range(len(list1)):
        print('------------>', list1[i])

        list1[i] = 1
        time.sleep(0.5)
    lock.release()


if __name__ == '__main__':
    t1 = threading.Thread(target=task1)
    t2 = threading.Thread(target=task2)

    t1.start()
    t2.start()
"""
结果
------------> 0
------------> 1
------------> 2
------------> 3
------------> 4
------------> 5
------------> 6
------------> 7
------------> 8
------------> 9
------------> 1
------------> 1
------------> 1
------------> 1
------------> 1
------------> 1
------------> 1
------------> 1
------------> 1
------------> 1
"""
```

> ### 死锁

死锁就是再开发过程中使用线程，在线程间共享多个资源的时候， 如果两个线程分别占据一部分资源并且同时等待对方的资源，就会造成死锁。

尽管死锁很少发生， 但是一旦发生就会造成应用的停止响应，程序不做任何事情

```python
from threading import Thread, Lock
import time

lockA = Lock()
lockB = Lock()


class MyThread1(Thread):
    def run(self):
        if lockA.acquire():
            print(f'{self.name}获得了A锁')
            time.sleep(0.1)
            if lockB.acquire():
                print(f"{self.name}获得了B锁")
                lockB.release()

            lockA.release()


class MyThread2(Thread):
    def run(self):
        if lockB.acquire():
            print(f'{self.name}获得了B锁')
            time.sleep(0.1)
            if lockA.acquire(timeout=5):
                print(f"{self.name}获得了B锁")
                lockA.release()

            lockB.release()


if __name__ == '__main__':
    t1 = MyThread1()
    t2 = MyThread2()
    t1.start()
    t2.start()

"""
结果：
Thread-1获得了A锁
Thread-2获得了B锁
Thread-1获得了B锁
"""

```

避免死锁：

1. 重构代码
2. 使用 timeout 参数

> ### 生产者与消费者模式

生产者与消费者模式是一种常用的多线程并发模型，用于解决生产者和消费者操作同一个缓冲区时可能出现的竞态条件问题。

在这种模式中，生产者线程往共享缓冲区（队列）中不断添加任务，而消费者线程则从缓冲区中取出任务并执行。生产者和消费者同时运行，并且必须协调它们的操作，以避免以下情况的发生：

1. 缓冲区空：消费者试图从空的缓冲区中取出数据，这时需要等待生产者将新的数据放入缓冲区中后再进行取出操作。

2. 缓冲区满：生产者试图向已经满的缓冲区中添加数据，这时需要等待消费者从缓冲区中取出数据后再进行添加操作。

为了协调生产者和消费者的操作，通常会使用一个中间层（缓冲区）来提供同步机制，保证生产者和消费者之间的顺序以及互斥访问。常见的同步机制包括互斥锁、条件变量等。

在 Python 中，可以使用 queue 模块来实现生产者消费者模型，其中 Queue 类提供了线程安全的队列操作，可以作为缓冲区使用。生产者通过 put 方法向队列中添加元素，消费者通过 get 方法从队列中取出元素，如果队列为空或者已满则会自动阻塞等待。此外，还可以使用 join 和 task_done 方法来控制线程的执行顺序。

```python

import threading
import time
import queue

# 创建一个空的队列作为缓冲区
buffer = queue.Queue(maxsize=10)

class ProducerThread(threading.Thread):
    def run(self):
        while True:
            # 循环添加任务到缓冲区中
            if buffer.full():
                print('Buffer is full, waiting...')
            item = time.time()  # 生产一个任务
            buffer.put(item, block=True, timeout=None)
            print(f'Produced item {item}')
            time.sleep(1)

class ConsumerThread(threading.Thread):
    def run(self):
        while True:
            # 循环从缓冲区中取出任务并执行
            if buffer.empty():
                print('Buffer is empty, waiting...')
            item = buffer.get(block=True, timeout=None)
            print(f'Consumed item {item}')
            time.sleep(2)
            buffer.task_done()  # 标识已经处理完一个任务

# 创建一个生产者线程和一个消费者线程
producer_thread = ProducerThread()
consumer_thread = ConsumerThread()

# 启动两个线程，并等待它们运行结束
producer_thread.start()
consumer_thread.start()

# 等待队列中剩余的任务被处理完后退出程序
buffer.join()
```

在上面的例子中，我们定义了一个生产者线程和一个消费者线程，并通过 queue.Queue 类来实现线程之间的同步。生产者线程通过 put 方法向队列中添加元素，消费者线程通过 get 方法从队列中取出元素并执行相应的任务。程序在没有任务可以处理时会自动等待，并且使用 join 方法来在所有任务执行完毕后结束程序。

> 协程

协程是一种轻量级的多任务处理方式，可以在单线程内实现并发。它是一种运行在用户空间的并发模型，相比于操作系统线程或进程等并发模型，协程具有以下优点：

轻量级：协程切换时只需要保存少量的上下文信息，因此开销小。

高效性：协程可以在一个线程内实现多个任务之间的切换，避免了线程间上下文切换所带来的额外开销。

灵活性：协程可以根据需要动态调整并发数量，更加适合动态变化的业务场景。

Python 提供了 asyncio 模块来支持协程，并提供了很多实用的方法和工具函数来简化协程编程。使用 async 关键字定义一个协程函数，它可以通过 await 关键字来挂起当前的执行，并等待另一个协程的执行结果。

```python

import asyncio

async def coroutine():
    print('Coroutine is running')
    await asyncio.sleep(1)  # 模拟耗时1秒的IO操作
    print('Coroutine is done')

loop = asyncio.get_event_loop()
loop.run_until_complete(coroutine())
```

在上面的示例中，我们使用 async 关键字定义了一个协程函数 coroutine，该函数内部使用 await 关键字来挂起当前的执行，并等待一个时间为 1 秒的模拟 IO 操作。然后，我们创建了一个事件循环并调用 run_until_complete 方法来运行协程，使其在事件循环中被执行。

总的来说，协程是一种独特的并发处理方式，可以在单线程内实现多个任务之间的切换，从而提高程序的并发能力和响应速度。虽然有些复杂度，但相比于线程和进程等并发模型，协程是更加轻量级和灵活的选择。
